# Ch03 データサイエンスプロジェクトの進め方


## 3-1 データサイエンスプロジェクトの流れ

CRISP-DM

- Business Understanding（ビジネス理解）
- Data Understanding（データ理解）
- Data Preparation（データ準備）
- Modeling（モデリング）
- Evaluation（評価）
- Deployment（実装）

&nbsp;

- Business Understanding（ビジネス理解）
  - (1)業務課題の把握（プロジェクト起案）
  - (2)分析方針の設計
- Data Understanding（データ理解）
  - (3)データの理解・収集
- Data Preparation（データ準備）
  - (4) データの加工
- Modeling（モデリング）
  - (5)データ分析・モデリング
- Evaluation（評価）
  - (6)分析結果の考察
- Deployment（実装）
  - (7)業務への適用

## 3-2 (1)業務課題の把握（プロジェクト起案）

- (a)対象業務の設定
- (b)業務課題の設定
- (c)ゴールおよびスコープの設定
- (d)作業内容・スケジュール・体制の検討
- (e)予算の確保

### 3-2-1 (a)対象業務の設定

- 企業の中にはさまざまな業務がある
- どの業務をデータサイエンスプロジェクトの対象とするかを決める

### 3-2-2 (b)業務課題の設定

- 対象業務のどんな業務課題を解決するかを決める
- 売上を上げるための業務課題（障壁）例
  - 新規の顧客が増えず、伸び悩んでいる
  - 既存の顧客が他社に取られ、離反が起きている
  - 顧客はそれなりにいるが、顧客単価が低い
  - 顧客はそれなりにいるが、利用頻度が低い
- 大きな課題から因数分解するイメージ

### 3-2-3 (c)ゴールおよびスコープの設定

- 業務課題に対して今回のプロジェクトのゴールおよびスコープで「何を」「どこまで」目指すかを決める
  - 「利用頻度の低い顧客」と「利用頻度の高い顧客」で、顧客属性の違いや購入商品の違いを可視化すること
  - 利用頻度を高めるための要因を発見すること
  - 要因分析の結果のもとに、利用頻度を高めるための施策を検討し、実際に施策を実施して効果の有無を検証すること

### 3-2-4 (d)作業内容・スケジュール・体制の検討

- プロジェクトのスコープに合わせてプロジェクトに必要な作業やスケジュールをWBS（Work Breakdown Structure: 作業分解構成図）に落とし込む

### 3-2-5 (e)予算の確保

- プロジェクトを進めのに必要な作業内容、スケジュール、体制、工数を示して、それを実施するのに必要な予算を確保する
  - 何の業務を解決しようとしているのか
  - 将来どの程度の投資対効果がみこめるのか

[Lumada 協創事例](https://www.hitachi.co.jp/products/it/lumada/stories/index.html)

## 3-3 (2)分析方針の設計

- (a)データ集計・可視化を中心に進めるパターン
- (b)機械学習を用いて進めるパターン

### 3-3-1 (a)データ集計・可視化を中心に進めるパターン

- 小売業で「POS(Pint of Sales)データを使って店舗の売上を増やす」というプロジェクト例
  - ある店舗の売上が低迷しているので、店舗売上を増やしたい
  - 周辺地域の店舗売上の傾向を分析して、どうしたら売上を増やせるかを分析したい
  - どんな商品が売れているのか、どんな顧客が来店しているのかを分析したい

### 3-3-2 (b)機械学習を用いて進めるパターン

- 小売業における「商品在庫の最適化」
  - 需要予測モデル

&nbsp;

- 機械学習
  - 教師あり学習
    - 回帰問題
    - 分類問題
  - 教師なし学習
    - クラスタリング
    - 次元削減
    - 外れ値検知
  - 強化学習

#### 3-3-2-1 目的変数および説明変数の設計

- 目的変数
  - 予測したい変数
  - 需要予測でいえば、販売個数
- 説明変数（特徴量）
  - 入力データとして使う変数
  - 需要予測でいえば、天気、気温、曜日（平日・休日）など

※入力データの特性がわかっていないため、説明変数の候補となるデータの一覧を洗い出す

#### 3-3-2-2 入力データの洗い出し

- 目的変数・説明変数を洗い出したら、分析に必要な入力データ群を検討する
  - 売上データ
  - 気象データなどオープンデータの収集

#### 3-3-2-3 目標指標や目標値の設定

- 需要予測として1日単位の売上個数を予測するのであれば、
  - 予測誤差としてどのくらいを目指すか／許容するか
  - 過去になんらかの方法で予測している場合には、それを上回ることを目標値にすることもある
- 仮決めしたうえで、分析しながら見直す（評価指標や目標値設定）

#### 3-3-2-4 運用を踏まえた分析設計

- 運用を踏まえた設計をする
  - 3か月後の予測をすべきか
  - 1週間後の予測をすべきか
  - 今日の午前／午後／夕方レベルでの予測をすべきか

## 3.4 (3)データの理解・収集

- 一般的には業務システムのDBMS
- 情報系システムにおけるDWH(Data WareHouse)
- データマート、Hadoopなどによるデータレイク（収集したデータを生データのまま）格納しておくストレージ、リポジトリ等
  - データ抽出条件
  - テーブル構成
  - データフォーマット
  - データの基礎集計情報（ユーザー数、データ期間）

## 3.5 (4)データの加工

- データの内容の確認
  - 指定した条件のデータの有無
  - 期待したデータの有無
- 複数のデータソースから集められてきた場合は、何らかのデータをキーとして結合する
- データごとに基礎集計を行い、可視化してデータの分布・特徴を確認する
- 外れ値（異常値）や欠損値の有無
  - 外れ値（異常値）: 大多数のデータから大きくハズレた値
  - 欠損値: データが含まれていない値

&nbsp;

- サンプルデータは早めに入手する
- 前処理の作業時間をなるべく短くする（プロジェクト期間の3~4割以下）
- 正解ラベルは本当に正しいか確かめる
- 異常値や外れ値は安易に補正をしない

### Column ドメイン知識の活用

- 欠損値・異常値が発生するよくあるケース
  - 小売業向けデータ分析において
    - ユーザー登録時に年齢や住所として故意に誤ったデータが入力されている
    - データ項目を途中から違う用途に使い出した
  - 設備・機器に関するデータ分析
    - マシンの不調により一時的にログが記録されていなかった
    - 何の要因もなくログが記録されていなかった
- 一般的な対処方法
  - データ誤入力: 対象ユーザーの削除、誕生日や郵便番号等から補正
  - データ項目の用途変更: データ項目の削除、直近のみ利用
  - マシンの一時的なログ欠損: 故障等と因果関係のある可能性があるのでそのまま利用
  - ログの完全にランダムな欠損: そのまま利用、もしくは補間する

## 3-6 (5)データ分析・モデリング

- (a)分析モデルの作成
- (b)分析モデルのチューニング

### 3-6-1 (a)分析モデルの作成

- 勾配Boosting
  - LightGBM
  - xgboost

### 3-6-2 (b)分析モデルのチューニング

- ハイパーパラメータのチューニング
- 特徴量エンジニアリング
  - 仮説ドリブン
    - 目的変数に影響を与えそうな特徴量の仮設を立てて作る
  - データドリブン
    - 各手法を用いてインプットするデータの特性に合わせて特徴量を作る
      - カテゴリー変数をキーにして集約した特徴量を作る
      - one-hotエンコーディング
      - 時系列データであれば、時間をシフトしたラグ特徴量を作る

&nbsp;

- 1つの手法にこだわらず分析する
- 分析作業で試行錯誤する場合、パラメータはすべて記録する
- ハイパーパラメータのチューニングは数回程度に留める
- モデルを構築する際は、精度だけでなく、業務への適用時の処理時間やメンテナンスコストも考慮する

## 3-7 (6)分析結果の考察

- (a)分析モデルの精度評価
- (b)分析結果の考察・説明

### 3-7-1 (a)分析モデルの精度評価

#### 3-7-1-1 回帰問題の評価

- MAE: Mean Absolute Error（平均絶対誤差）
  - 誤差の総量を評価したい
- MSE: Mean Squared Error（平均二乗誤差）
- RMSE: Root Mean Squared Error（平均二乗誤差の平方根）
  - 大きく外れるほどペナルティを大きくしたい
- CV: Cross Validation（交差検証）
  - K-Fold Cross Validation（K- 分割交差検証）

#### 3-7-1-2 分類問題の評価

Confusion Matrix（混合行列）

|||>|予測結果|
|:-:|:-:|:-:|:-:|
|||Positive|Negative|
|**正解ラベル**|Positive|TP: True Positive（真陽性）|FN: False Negative（偽陰性）|
|^|Negative|FP: False Positive（偽陽性）|TN: False Negative（偽陰性）|

- TP: True Positive（真陽性）
  - Positive と予測して正解ラベルも Positive だった場合
- FP: False Positive（偽陽性）
  - Positive と予測して正解ラベルは Negative だった場合
- FN: False Negative（偽陰性）
  - Negative と予測して正解ラベルは Positive だった場合
- TN: False Negative（偽陰性）
  - Negative と予測して正解ラベルも Negative だった場合

&nbsp;

- AUC: Area Under the Curve
- ROC: Receiver Operating Characteristic
  - TPR: True Positive Rate（真陽性率）
  - FPR: False Positive Rate（偽陽性率）

### 3.7.2 (b)分析結果の考察・説明

- 目標値に対してどこまで到達したか

## 3.8 (7)業務への適用

- 要因分析など1回限りの分析であれば、結果を踏まえて業務を見直してもらい、施策を実行してその効果を確認する
- 需要予測など業務のなかで継続的に使う分析モデルの場合、分析モデルを動かすための本番システムを構築する
  - オンプレミスなシステムを構築する場合
  - パブリッククラウドを活用して構築する場合
  - 分析モデルの精度を監視し続け、精度が下がってきた場合には再学習するなどの対策が必要
